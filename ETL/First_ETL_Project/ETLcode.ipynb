{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c186a9a5-01f1-4b29-b9e9-6ebfda35e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84145c5c-455b-417e-8f8c-e27d5af3b63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/jxdqcbn16yv2ckg0lz2klm7m0000gn/T/ipykernel_46731/1362752556.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  exctracted_data = pd.concat([exctracted_data,pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True)\n",
      "/var/folders/_q/jxdqcbn16yv2ckg0lz2klm7m0000gn/T/ipykernel_46731/1362752556.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe,pd.DataFrame([{'name':name,'height':height,'weight':weight}])], ignore_index=True)\n",
      "/var/folders/_q/jxdqcbn16yv2ckg0lz2klm7m0000gn/T/ipykernel_46731/1362752556.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe,pd.DataFrame([{'name':name,'height':height,'weight':weight}])], ignore_index=True)\n",
      "/var/folders/_q/jxdqcbn16yv2ckg0lz2klm7m0000gn/T/ipykernel_46731/1362752556.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe,pd.DataFrame([{'name':name,'height':height,'weight':weight}])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create a logfile to save logs and a csv file to store the transformed data\n",
    "log_file='logfile.txt'\n",
    "traget_file = 'transformed_data.csv'\n",
    "\n",
    "#Extract data from CSV Files\n",
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe\n",
    "\n",
    "#Extract data from JSON\n",
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process,lines=True)\n",
    "    return dataframe\n",
    "\n",
    "#Extract from xml files\n",
    "def extract_from_xml(file_to_process):\n",
    "    #Create a empty dataframe so that we can append the data extracted to that datframe\n",
    "    dataframe = pd.DataFrame(columns=['name','height','weight'])  \n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        name = person .find('name').text\n",
    "        height = float(person .find('height').text)\n",
    "        weight = float(person .find('weight').text)\n",
    "        dataframe = pd.concat([dataframe,pd.DataFrame([{'name':name,'height':height,'weight':weight}])], ignore_index=True)\n",
    "    return dataframe\n",
    "\n",
    "#Extract all the dataframes into a single dataframe\n",
    "def extract():\n",
    "    #Create an empty dataframe to store all the dataframes\n",
    "    exctracted_data = pd.DataFrame(columns=['name','height','weight'])\n",
    "    #Process all csv files\n",
    "    for csvfile in glob.glob(\"*.csv\"):\n",
    "        if csvfile!=traget_file:\n",
    "            exctracted_data = pd.concat([exctracted_data,pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True)\n",
    "    #Process al json files\n",
    "    for json in glob.glob(\"*.json\"):\n",
    "        exctracted_data = pd.concat([exctracted_data,pd.DataFrame(extract_from_json(json))],ignore_index = True)\n",
    "    #Process all XML files\n",
    "    for xmlfile in glob.glob(\"*.xml\"):\n",
    "        exctracted_data = pd.concat([exctracted_data,pd.DataFrame(extract_from_xml(xmlfile))],ignore_index=True)\n",
    "    return exctracted_data\n",
    "#Transform height from inches to meters and weight from kilograms from pounds\n",
    "def transform(data): \n",
    "    '''Convert inches to meters and round off to two decimals \n",
    "    1 inch is 0.0254 meters '''\n",
    "    data['height'] = round(data.height * 0.0254,2) \n",
    " \n",
    "    '''Convert pounds to kilograms and round off to two decimals \n",
    "    1 pound is 0.45359237 kilograms '''\n",
    "    data['weight'] = round(data.weight * 0.45359237,2) \n",
    "    \n",
    "    return data \n",
    "\n",
    "# Load the data to a our taget csv file\n",
    "def load_data(target_file,transformed_data):\n",
    "    transformed_data.to_csv(target_file)\n",
    "\n",
    "#Record logging operations\n",
    "def log_process(message):\n",
    "    timestamp_format = \"%Y-%h-%d%H:%M:%S\" \"year-month-day-hour-minutes-seconds\"\n",
    "    now = datetime.now() #get current time stamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(log_file,\"a\") as f:\n",
    "        f.write(timestamp + ','+ message + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "# Log the initializatio of ETL process\n",
    "log_process(\"ETL job started\")\n",
    "\n",
    "#log the begining of extraction\n",
    "log_process(\"Exctraction Phase started\")\n",
    "extracted_data = extract()\n",
    "\n",
    "#log completion of extraction\n",
    "log_process(\"Extraction phase Ended\")\n",
    "\n",
    "#log begining of transformation\n",
    "log_process(\"Tranformation phase started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "\n",
    "#log ending of transormation\n",
    "log_process(\"Transformation phase Ended\")\n",
    "\n",
    "#Log the begining of Loading data\n",
    "log_process(\"Load phase started\")\n",
    "load_data(traget_file,transformed_data)\n",
    "\n",
    "#log ending of Load\n",
    "log_process(\"Load phase Ended\")\n",
    "\n",
    "#Finally log completion of ETL Process\n",
    "log_process(\"ETL Job Ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18838dc-4328-478e-ba1a-835c3dcc7444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DE)",
   "language": "python",
   "name": "de"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
